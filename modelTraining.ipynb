{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to train the bike availability models, using historic availability and weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# connect to database\n",
    "engine = create_engine(\"mysql://admin:jcdgroup21@jcdecaux-bikes.cti0lbnfidpl.us-east-1.rds.amazonaws.com:3306/jcdecaux-bikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tables\n",
    "available = pd.read_sql_table(\"available\", engine)\n",
    "stations = pd.read_sql_table(\"stations\", engine)\n",
    "weather = pd.read_sql_table(\"weather\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample weather to average over 30 min intervals\n",
    "weather_resampled = weather.set_index(\"time\").resample(\"30min\").agg({'temp': np.mean, 'wind_speed': np.mean, 'humidity': np.mean, 'type': lambda x: (stats.mode(x)[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to hold prepared per station data\n",
    "station = {}\n",
    "\n",
    "# group available table by station number\n",
    "grouped = available.groupby(available.number)\n",
    "\n",
    "# get a list of all station numbers\n",
    "stationNumbers = stations.number.unique()\n",
    "\n",
    "# for each station\n",
    "for i in stationNumbers:\n",
    "    \n",
    "    # collect all data entries for this station into new dataframe\n",
    "    df_new = grouped.get_group(i)\n",
    "    \n",
    "    # drop duplicates from the dataframe\n",
    "    df_new = df_new.drop_duplicates()\n",
    "    \n",
    "    # resample availability to average over 30 min intervals\n",
    "    df_new = df_new.set_index(\"last_update\").resample(\"30min\").mean()\n",
    "    \n",
    "    # merge with weather dataframe\n",
    "    merge = df_new.merge(weather_resampled, left_index = True, right_index = True)\n",
    "    \n",
    "    # create day, hour and minute categorical columns\n",
    "    merge[\"day\"] = merge.index.dayofweek\n",
    "    merge[\"hour\"] = merge.index.hour\n",
    "    merge[\"Minute\"] = merge.index.minute\n",
    "    \n",
    "    # remove nan rows, time periods when stations are closed\n",
    "    merge = merge.dropna()\n",
    "    \n",
    "    # store in dictionary with station number as key\n",
    "    station[i] = merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaned data is now stored in a dictionary called 'station'\n",
    "\n",
    "access the required station using the station number as key value, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>available_bike_stands</th>\n",
       "      <th>available_bikes</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>type</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_update</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-03 00:00:00</th>\n",
       "      <td>59.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>277.930</td>\n",
       "      <td>3.09</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03 05:00:00</th>\n",
       "      <td>59.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>277.840</td>\n",
       "      <td>2.57</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03 05:30:00</th>\n",
       "      <td>59.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>277.810</td>\n",
       "      <td>2.57</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03 06:00:00</th>\n",
       "      <td>59.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>277.685</td>\n",
       "      <td>2.57</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03 06:30:00</th>\n",
       "      <td>59.0</td>\n",
       "      <td>9.25</td>\n",
       "      <td>10.75</td>\n",
       "      <td>277.660</td>\n",
       "      <td>2.57</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number  available_bike_stands  available_bikes     temp  \\\n",
       "last_update                                                                    \n",
       "2021-03-03 00:00:00    59.0                   9.00            11.00  277.930   \n",
       "2021-03-03 05:00:00    59.0                   9.00            11.00  277.840   \n",
       "2021-03-03 05:30:00    59.0                   9.00            11.00  277.810   \n",
       "2021-03-03 06:00:00    59.0                   9.00            11.00  277.685   \n",
       "2021-03-03 06:30:00    59.0                   9.25            10.75  277.660   \n",
       "\n",
       "                     wind_speed  humidity    type  day  hour  Minute  \n",
       "last_update                                                           \n",
       "2021-03-03 00:00:00        3.09      87.0  Clouds    2     0       0  \n",
       "2021-03-03 05:00:00        2.57      89.0  Clouds    2     5       0  \n",
       "2021-03-03 05:30:00        2.57      93.0  Clouds    2     5      30  \n",
       "2021-03-03 06:00:00        2.57      93.0  Clouds    2     6       0  \n",
       "2021-03-03 06:30:00        2.57      93.0  Clouds    2     6      30  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station[59].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedStation = {}\n",
    "for i in stationNumbers:\n",
    "    type_encoder = OneHotEncoder()\n",
    "    type_encoded = type_encoder.fit_transform(np.array(station[i][\"type\"]).reshape(-1,1))\n",
    "    type_encoded = pd.DataFrame(type_encoded.toarray(), columns = [category for category in type_encoder.categories_[0]])\n",
    "    temp = station[i].reset_index(drop=True)\n",
    "    encodedStation[i] = pd.concat([type_encoded, temp[[\"day\", \"hour\",\"Minute\", \"temp\", \"humidity\", \"wind_speed\"]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yDataStation = {}\n",
    "for i in stationNumbers:\n",
    "    yDataStation[i] = station[i][\"available_bikes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor (testing on one station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encodedStation[90]\n",
    "Y = yDataStation[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(max_depth = 30)\n",
    "reg.fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.4473012109804833\n",
      "R2:  0.6242498254319916\n",
      "MAE:  2.5211926392380026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "print(\"RMSE: \", mean_squared_error(Y_test, Y_pred, squared = False))\n",
    "print(\"R2: \", r2_score(Y_test, Y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These errors may not be the best but we have decided that with the limited time we were given for model training and the envirnoment around the pandemic messing with network usage, we will not be getting much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to hold the models\n",
    "station_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for each station, train model\n",
    "for number in list(encodedStation.keys()):\n",
    "    X_data = encodedStation[number]\n",
    "    y_data = yDataStation[number]\n",
    "    reg = RandomForestRegressor()\n",
    "    # the hyper prarmeters i used\n",
    "    params = {\"criterion\": [\"mse\", \"mae\"], \"max_depth\": [3,4,5,6], \"min_samples_split\" : [2,3,4,5], \"bootstrap\":[True, False]}\n",
    "    # grid search\n",
    "    clf = GridSearchCV(estimator=reg,\n",
    "                 param_grid=params,\n",
    "                 cv = 5,\n",
    "                 verbose = True,\n",
    "                 n_jobs = -1)\n",
    "\n",
    "    # training\n",
    "    clf.fit(X_data, y_data)\n",
    "\n",
    "    # the model to be saved\n",
    "    model = clf.best_estimator_\n",
    "    station_models[number] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in station_models.keys():\n",
    "    model = station_models[number]\n",
    "    # Here is how you save using pickle\n",
    "    filename = 'models/station{id}_model.sav'.format(id = number)\n",
    "    # model is the best estimator from the gridsearch\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
